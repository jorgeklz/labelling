{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fase Final Creacion Modelo LSI.ipynb","provenance":[],"authorship_tag":"ABX9TyPxjPBp5FPEGCqXVt0P6tLO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTh4GxJk4ct1","executionInfo":{"status":"ok","timestamp":1630849636505,"user_tz":300,"elapsed":308661,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"a56c6adf-6938-4e08-dcf4-0c9798be2c8c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"cU504rYCiFyG"},"source":["Librerias"]},{"cell_type":"code","metadata":{"id":"fT4srlL34nzw"},"source":["import re, string, unicodedata\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import collections\n","\n","import nltk\n","from nltk import word_tokenize\n","from nltk import download\n","from nltk.corpus import stopwords\n","\n","\n","%pip install stanza\n","import stanza\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V43-W8D84t63"},"source":["download('stopwords')\n","download('punkt')\n","stanza.download('es')\n","nlp = stanza.Pipeline('es')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieCuhial4wbX"},"source":["def eliminar_textos_basura(texto):\n","    # eliminar emojis: elimina todo lo que este en <>. \n","    texto_procesado = re.sub('<.*?>', ' ', texto)\n","    # convertir a minusculas\n","    texto_procesado = texto_procesado.lower()\n","    # remover @usuario\n","    texto_procesado = re.sub('@[^\\s]+',' ',texto_procesado)\n","    # remover RT\n","    texto_procesado = re.sub('rt   ',' ',texto_procesado)\n","    texto_procesado = re.sub('rt',' ',texto_procesado)\n","    texto_procesado = re.sub('rt ',' ',texto_procesado)\n","    # remover numeros\n","    texto_procesado = re.sub(\"\\d+\", \"\", texto_procesado)\n","    # texto_procesado = re.sub(r'http\\S+', ' ', texto_procesado)\n","    texto_procesado = re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", texto_procesado)\n","    # reemplazar todos los caracteres que no saen alfanuméricos con espacios\n","    texto_procesado = re.sub(r'[^a-zA-Z0-9ÑñÁáÉéÍíÓóÚú\\s]', ' ', texto_procesado)\n","    \n","    return texto_procesado\n","\n","def eliminar_stop_words(texto):\n","    # obtener lista de stopwords\n","    stop_words = set(stopwords.words('spanish')) \n","    stop_words.remove('no')\n","    #separar el texto por palabras\n","    palabras = word_tokenize(texto) \n","    # dejar solo palabras que no sean stopwords\n","    texto_sin_sw = [w for w in palabras if not w in stop_words] \n","    #  convertir en una sola cadena la lista de palabras\n","    texto_sin_sw = ' '.join(texto_sin_sw)\n","\n","    return texto_sin_sw \n","\n","def remove_non_ascii(word):\n","    \"\"\"Remueve caracteres no ASCII\"\"\"\n","    new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","    \n","    return new_word\n","\n","def establecer_lema(text):\n","  doc = nlp(text)\n","  new = ''\n","  for sent in doc.sentences:\n","    for word in sent.words:\n","      new = new + word.lemma\n","      new = new + ' '\n","\n","  return new\n","\n","#Convierto cada tweet del dataset en un vector de palabras\n","from nltk import word_tokenize\n","def ConvertirData(corpusBase):\n","  textos = []\n","  for y in [corpusBase['text'][i] for i in range(len(corpusBase))]:\n","      doc = word_tokenize(y)\n","      textos.append(doc)\n","  return textos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tr8xh7ik5B-Y"},"source":["def Knn(Matriz, k):\n","  labels = DataFinal['tipo']\n","  pred_label = []\n","  etiquetar = []\n","  indice = 0\n","  for x in labels:\n","      if(indice != len(labels)-1):\n","        if(Matriz[indice]<=0.20): #Filtro que asigan directament 0 cuando el valor de comparacion sera cero o menor a cero\n","          etiquetar.append((Matriz[indice], 0))\n","        else:\n","          etiquetar.append((Matriz[indice], x))\n","      indice += 1\n","  etiquetar.sort(reverse=True)\n","  neighbors = etiquetar[:k]\n","  votes = []\n","  for neighbor in neighbors:\n","            votes.append(neighbor[1])\n","  counter = collections.Counter(votes) #Determina el que mas se repite\n","  pred_label.append(counter.most_common()[0][0])\n","  return pred_label\n","\n","def EtiquetaEnTexto(valor):\n","  if valor[0]==1:\n","    return 'emergencia'\n","  else:\n","    return 'no emergencia'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RRZzHlZk45XC"},"source":["def ProcesarTweet(Tweet):\n","  Procesado = eliminar_textos_basura(Tweet)\n","  Procesado = eliminar_stop_words(Procesado)\n","  Procesado = remove_non_ascii(Procesado)\n","  Procesado = establecer_lema(Procesado)\n","  return Procesado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJkoebqleUvf"},"source":["RECURSO"]},{"cell_type":"code","metadata":{"id":"djAaWiDu5E_2"},"source":["DataFinal = pd.read_excel('/content/gdrive/My Drive/Colab Notebooks/Reporte_tweets_Ecuador/4DataFinalLemaFiltro.xlsx')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dLOfj9mRqqwV"},"source":["CREACIÓN DEL MODELO \n"]},{"cell_type":"code","metadata":{"id":"PzGu6ZC-rBzI"},"source":["from gensim import corpora\n","from gensim.models import LsiModel\n","from gensim.models import TfidfModel\n","from gensim.similarities import MatrixSimilarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qy_dHUke5I8R"},"source":["'''\n","Función que recibira el tweet para generar las comparaciones con los tweets de la data en base al modelo\n","'''\n","def modeloLSI(tweet):\n","  Tweet = word_tokenize(ProcesarTweet(tweet)) #Se Preprocesa el tweet y se tokeniza el texto\n","  \n","  if len(Tweet) <= 2: #Se valida que el tweet preprocesado tenga un minino de palabras\n","    Tweet = ['vacio']  #Se le asigna el texto 'vacio' el cual sera detectado como no emergencia\n","  \n","  tweet_Dic = DiccioLSI.doc2bow(Tweet) #Se estructura el tweet en función al diccionario del modelo\n","  sim = MatrizSimLSI[modelLSI[tweet_Dic]] #Se genera un nuevo vector que contiene el nivel de similitud del nuevo tweet con cada tweet del dataset\n","  \n","  Valor_Similitud = [] \n","  for i in range(len(sim)):\n","    a = ('%.2f' % sim[i]) #Se redondea cada valor del vector de similitud creado para establecer un mismo formato a todos los valores\n","    Valor_Similitud.append(float(a))\n","  \n","  return Valor_Similitud"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KxfePxA5MBJ"},"source":["'''\n","Determina la etiqueta del nuevo tweet por cada knn establecido\n","'''\n","def EtiquetarModelLSI(tweet):\n","  Similaridad= modeloLSI(tweet)\n","  k_1 = Knn(Similaridad, 1)\n","  k_3 = Knn(Similaridad, 3)\n","  k_5 = Knn(Similaridad, 5)\n","  k_7 = Knn(Similaridad, 7)\n","  k_9 = Knn(Similaridad, 9)\n","  k_11 = Knn(Similaridad, 11)\n","  return k_1, k_3, k_5, k_7, k_9, k_11 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPcHB5aYpdKv","executionInfo":{"status":"ok","timestamp":1630849859446,"user_tz":300,"elapsed":91079,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"dcba1640-99ac-4c8a-a9ea-47fc9d7db840"},"source":["'''\n","En consideración a que el modelo cada que se crea genera resultados diferentes, se establece la creación de 12 variantes \n","'''\n","textos = ConvertirData(DataFinal) #Se tokeniza cada tweet de la data\n","for a in range(12):\n","  #Creación del modelo\n","  dictionary_textos = corpora.Dictionary(textos) #Se genera el diccionario en base a la data\n","  corpus_gensim_textos = [dictionary_textos.doc2bow(doc) for doc in textos]\n","  tfidf_textos = TfidfModel(corpus_gensim_textos) #Se crea el modelo de frecuencia de palabras  \n","  corpus_tfidf_textos = tfidf_textos[corpus_gensim_textos] #Se genera una nueva corpus en base al modelo creado\n","  lsi_textos = LsiModel(corpus_tfidf_textos, id2word=dictionary_textos, num_topics=700) #Se crea el modelo  LSI usando la corpus que se genero\n","  lsi_index_textos= MatrixSimilarity(lsi_textos[corpus_tfidf_textos]) #Se establece la matriz de similaridad\n","\n","  text1= '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/DiccionarioLSI'+str(a)+'.pickle'\n","  text2= '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/MatrizSimilaridadLSI'+str(a)+'.pickle'\n","  text3= '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/ModelLSI'+str(a)+'.model'\n","\n","  pickle.dump(dictionary_textos, open(text1, 'wb'))\n","  pickle.dump(lsi_index_textos, open(text2, 'wb'))\n","  pickle.dump(lsi_textos, open(text3, 'wb'))\n","\n","  print('MODELO CREADO LSI '+str(a))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MODELO CREADO LSI 0\n","MODELO CREADO LSI 1\n","MODELO CREADO LSI 2\n","MODELO CREADO LSI 3\n","MODELO CREADO LSI 4\n","MODELO CREADO LSI 5\n","MODELO CREADO LSI 6\n","MODELO CREADO LSI 7\n","MODELO CREADO LSI 8\n","MODELO CREADO LSI 9\n","MODELO CREADO LSI 10\n","MODELO CREADO LSI 11\n"]}]},{"cell_type":"markdown","metadata":{"id":"vTFtfVrEfILA"},"source":["PRUEBAS DE LAS VARIANTES DEL MODELO"]},{"cell_type":"code","metadata":{"id":"-tI-jvSZmiht"},"source":["import pandas as pd\n","import numpy as np\n","import collections\n","from sklearn import datasets, metrics\n","\n","def EmplearMetricasDeValidacion(DataPrueba, Modelo, columnas):\n","  metric1 = []\n","  metric2 = []\n","  metric3 = []\n","  metric4 = []\n","  metric5 = []\n","\n","  re = GenerarResultadosModelo(DataPrueba, Modelo)\n","  #k1\n","  metric1.append(metrics.accuracy_score(re[0], re[1]))\n","  metric2.append(metrics.precision_score(re[0], re[1]))\n","  metric3.append(metrics.recall_score(re[0], re[1]))\n","  #metric4.append(metrics.f1_score(re[0], re[1]))\n","  metric5.append(metrics.log_loss(re[0], re[1]))\n","  #k3\n","  metric1.append(metrics.accuracy_score(re[0], re[2]))\n","  metric2.append(metrics.precision_score(re[0], re[2]))\n","  metric3.append(metrics.recall_score(re[0], re[2]))\n","  #metric4.append(metrics.f1_score(re[0], re[2]))\n","  metric5.append(metrics.log_loss(re[0], re[2]))\n","  #k5\n","  metric1.append(metrics.accuracy_score(re[0], re[3]))\n","  metric2.append(metrics.precision_score(re[0], re[3]))\n","  metric3.append(metrics.recall_score(re[0], re[3]))\n","  #metric4.append(metrics.f1_score(re[0], re[3]))\n","  metric5.append(metrics.log_loss(re[0], re[3]))\n","  #k7\n","  metric1.append(metrics.accuracy_score(re[0], re[4]))\n","  metric2.append(metrics.precision_score(re[0], re[4]))\n","  metric3.append(metrics.recall_score(re[0], re[4]))\n","  #metric4.append(metrics.f1_score(re[0], re[4]))\n","  metric5.append(metrics.log_loss(re[0], re[4]))\n","\n","  #k9\n","  metric1.append(metrics.accuracy_score(re[0], re[5]))\n","  metric2.append(metrics.precision_score(re[0], re[5]))\n","  metric3.append(metrics.recall_score(re[0], re[5]))\n","  #metric4.append(metrics.f1_score(re[0], re[5]))\n","  metric5.append(metrics.log_loss(re[0], re[5]))\n","\n","  #k11\n","  metric1.append(metrics.accuracy_score(re[0], re[6]))\n","  metric2.append(metrics.precision_score(re[0], re[6]))\n","  metric3.append(metrics.recall_score(re[0], re[6]))\n","  #metric4.append(metrics.f1_score(re[0], re[6]))\n","  metric5.append(metrics.log_loss(re[0], re[6]))\n","\n","  resultado=[metric1,metric2,metric3,metric5]\n","\n","  Final = pd.DataFrame(resultado,columns=columnas)\n","  Final.insert(0,\"METRICAS VALIDACION\",['ACURRACY_SCORE','PRECISIÓN_SCORE','RECALL_SCORE','LOG_LOSS'],True)\n","  \n","  return Final\n","\n","def GenerarResultadosModelo(DataN, modelo):\n","  Data = DataN\n","  Reemplazo = Data['tipo'].replace(['emergencia'], 1).replace(['no emergencia'], 0)\n","  Data['tipo'] = Reemplazo\n","  text = list(Data['New_Tweet'])\n","  \n","  prediccion1 = []\n","  prediccion2 = []\n","  prediccion3 = []\n","  prediccion4 = []\n","  prediccion5 = []\n","  prediccion6 = []\n","\n","  for a in text:\n","    metodo= modelo(a)\n","    prediccion1.append(metodo[0])\n","    prediccion2.append(metodo[1])\n","    prediccion3.append(metodo[2])\n","    prediccion4.append(metodo[3])\n","    prediccion5.append(metodo[4])\n","    prediccion6.append(metodo[5])\n","  test_final = list(Data['tipo'])\n","\n","  return  test_final, prediccion1, prediccion2, prediccion3, prediccion4, prediccion5, prediccion6 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsduVMQkmrfv"},"source":["#Generar Reportes que contengan los resultados de las metricas de validación de cada una de las variantes del modelo\n","import pickle\n","DataNivelada = pd.read_excel('/content/gdrive/My Drive/Colab Notebooks/Tweets_Etiquetados/New_DataPrueba_Total.xlsx')\n","\n","Data = []\n","\n","for a in range(12):\n","  \n","  txt1 = '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/ModelLSI'+str(a)+'.model'\n","  txt2 = '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/DiccionarioLSI'+str(a)+'.pickle'\n","  txt3 = '/content/gdrive/My Drive/Colab Notebooks/MODELOLSI/Todos5/MatrizSimilaridadLSI'+str(a)+'.pickle'\n","\n","  modelLSI = pickle.load(open(txt1,'rb'))\n","  DiccioLSI = pickle.load(open(txt2,'rb'))\n","  MatrizSimLSI = pickle.load(open(txt3,'rb'))\n","\n","  LSI = EmplearMetricasDeValidacion(DataNivelada, EtiquetarModelLSI, ['lsi_1','lsi_3','lsi_5','lsi_7','lsi_9','lsi_11'])\n","  txtData = 'Verificacion_Modelo_LSI_'+str(a)+'.xlsx'\n","  print('ENTRO: ',a)\n","  Data.append(LSI)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LgIQly2km4jE"},"source":["#Guardar Reportes, el cual contara con las metricas de validación de cada uno de las variantes del modelo\n","Data[0].to_excel('Verificacion_Modelo_LSI_0.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_0.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[1].to_excel('Verificacion_Modelo_LSI_1.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_1.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[2].to_excel('Verificacion_Modelo_LSI_2.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_2.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[3].to_excel('Verificacion_Modelo_LSI_3.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_3.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[4].to_excel('Verificacion_Modelo_LSI_4.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_4.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[5].to_excel('Verificacion_Modelo_LSI_5.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_5.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[6].to_excel('Verificacion_Modelo_LSI_6.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_6.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[7].to_excel('Verificacion_Modelo_LSI_7.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_7.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[8].to_excel('Verificacion_Modelo_LSI_8.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_8.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[9].to_excel('Verificacion_Modelo_LSI_9.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_9.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[10].to_excel('Verificacion_Modelo_LSI_10.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_10.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n","\n","Data[11].to_excel('Verificacion_Modelo_LSI_11.xlsx', index=False)\n","!cp Verificacion_Modelo_LSI_11.xlsx '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NvX3JIofeIB"},"source":["Análisis de Resultados para determinar la mejor variante del Modelo\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"1xUyicrCqiOb"},"source":["#Cargar los resultados de validación de las variantes del modelo\n","DataModel = []\n","for a in range(12): \n","  txt = 'Verificacion_Modelo_LSI_'+str(a)+'.xlsx'\n","  txt2= '/content/gdrive/My Drive/Colab Notebooks/ANALIZAR/Todo6/'+txt\n","  DataModel.append(pd.read_excel(txt2)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZMKPZzstRFY"},"source":["Lsi_5 = []\n","Lsi_7 = []\n","Lsi_9 = []\n","Lsi_11 = []\n","for a in range(9):\n","  Lsi_5.append([DataModel[a]['lsi_5'][0],a])\n","  Lsi_7.append([DataModel[a]['lsi_7'][0],a])\n","  Lsi_9.append([DataModel[a]['lsi_9'][0],a])\n","  Lsi_11.append([DataModel[a]['lsi_11'][0],a])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EiTIMF01zgT","executionInfo":{"status":"ok","timestamp":1630854351147,"user_tz":300,"elapsed":254,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"94cd8673-054e-40e3-8ead-bdf855e421a1"},"source":["Lsi_5.sort(reverse=True)\n","Lsi_5"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.9, 6],\n"," [0.89875, 1],\n"," [0.8975, 7],\n"," [0.89625, 8],\n"," [0.8925, 5],\n"," [0.8925, 3],\n"," [0.89125, 4],\n"," [0.89, 2],\n"," [0.89, 0]]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VR8exkr2z4Mi","executionInfo":{"status":"ok","timestamp":1630854360799,"user_tz":300,"elapsed":248,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"258092d4-eb3d-451b-9ac9-a6244782590f"},"source":["Lsi_7.sort(reverse=True)\n","Lsi_7"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.905, 0],\n"," [0.9025, 8],\n"," [0.9025, 3],\n"," [0.89875, 7],\n"," [0.89875, 5],\n"," [0.8975, 1],\n"," [0.895, 6],\n"," [0.895, 2],\n"," [0.89375, 4]]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQPTYnRNwUqP","executionInfo":{"status":"ok","timestamp":1630854363349,"user_tz":300,"elapsed":241,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"1634a06a-dd30-4236-bbb3-cdf96c98d0cf"},"source":["Lsi_9.sort(reverse=True)\n","Lsi_9"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.89625, 3],\n"," [0.895, 6],\n"," [0.89375, 0],\n"," [0.89125, 8],\n"," [0.89125, 2],\n"," [0.89, 4],\n"," [0.88875, 1],\n"," [0.8875, 7],\n"," [0.885, 5]]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9B28SlhwWrs","executionInfo":{"status":"ok","timestamp":1630854368492,"user_tz":300,"elapsed":244,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"d7a37059-c50f-45b1-f4f4-efa775098fca"},"source":["Lsi_11.sort(reverse=True)\n","Lsi_11"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.89375, 0],\n"," [0.88875, 6],\n"," [0.88875, 5],\n"," [0.88875, 4],\n"," [0.88875, 2],\n"," [0.88625, 8],\n"," [0.88625, 3],\n"," [0.8825, 7],\n"," [0.88125, 1]]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"kIAwq1xF2uAN","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1630854398611,"user_tz":300,"elapsed":250,"user":{"displayName":"Jandry Hernaldo Franco Cantos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uZvGqTHeVZ0-RA-lrusQFoFM-DYnIvGafuJ=s64","userId":"06035716384649426644"}},"outputId":"902e0a36-67b8-42ea-e5a7-e1d5ed066851"},"source":["'''\n","Por lo tanto la mejor variante del modelo es la primera (0), con un K=7\n","'''\n","DataModel[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>METRICAS VALIDACION</th>\n","      <th>lsi_1</th>\n","      <th>lsi_3</th>\n","      <th>lsi_5</th>\n","      <th>lsi_7</th>\n","      <th>lsi_9</th>\n","      <th>lsi_11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ACURRACY_SCORE</td>\n","      <td>0.818750</td>\n","      <td>0.870000</td>\n","      <td>0.890000</td>\n","      <td>0.905000</td>\n","      <td>0.893750</td>\n","      <td>0.893750</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PRECISIÓN_SCORE</td>\n","      <td>0.792079</td>\n","      <td>0.852417</td>\n","      <td>0.870886</td>\n","      <td>0.890026</td>\n","      <td>0.873737</td>\n","      <td>0.877551</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RECALL_SCORE</td>\n","      <td>0.839895</td>\n","      <td>0.879265</td>\n","      <td>0.902887</td>\n","      <td>0.913386</td>\n","      <td>0.908136</td>\n","      <td>0.902887</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LOG_LOSS</td>\n","      <td>6.260237</td>\n","      <td>4.490099</td>\n","      <td>3.799316</td>\n","      <td>3.281227</td>\n","      <td>3.669795</td>\n","      <td>3.669793</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  METRICAS VALIDACION     lsi_1     lsi_3  ...     lsi_7     lsi_9    lsi_11\n","0      ACURRACY_SCORE  0.818750  0.870000  ...  0.905000  0.893750  0.893750\n","1     PRECISIÓN_SCORE  0.792079  0.852417  ...  0.890026  0.873737  0.877551\n","2        RECALL_SCORE  0.839895  0.879265  ...  0.913386  0.908136  0.902887\n","3            LOG_LOSS  6.260237  4.490099  ...  3.281227  3.669795  3.669793\n","\n","[4 rows x 7 columns]"]},"metadata":{},"execution_count":23}]}]}